{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shreyanshg/dungeons-and-dragons-campaign-assistant?scriptVersionId=256320513\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"353733d0","metadata":{"id":"Tce3stUlHN0L","papermill":{"duration":0.006401,"end_time":"2025-08-16T14:52:06.952519","exception":false,"start_time":"2025-08-16T14:52:06.946118","status":"completed"},"tags":[]},"source":["##### Copyright 2025 Google LLC."]},{"cell_type":"code","execution_count":1,"id":"b2ab9feb","metadata":{"cellView":"form","execution":{"iopub.execute_input":"2025-08-16T14:52:06.965919Z","iopub.status.busy":"2025-08-16T14:52:06.965336Z","iopub.status.idle":"2025-08-16T14:52:06.971854Z","shell.execute_reply":"2025-08-16T14:52:06.970662Z"},"id":"tuOe1ymfHZPu","papermill":{"duration":0.015951,"end_time":"2025-08-16T14:52:06.974244","exception":false,"start_time":"2025-08-16T14:52:06.958293","status":"completed"},"tags":[]},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","id":"2d3efcf0","metadata":{"id":"CsVPnR8VbXE6","papermill":{"duration":0.00552,"end_time":"2025-08-16T14:52:06.985792","exception":false,"start_time":"2025-08-16T14:52:06.980272","status":"completed"},"tags":[]},"source":["# An Agent That Answers Dungeons & Dragons Questions with Grounded Context\n","Welcome to your custom Generative AI notebook, where we build an intelligent assistant that can answer natural language questions about Dungeons & Dragons adventures—powered by the Gemini API and grounded in the actual source PDFs. This notebook showcases a Retrieval-Augmented Generation (RAG) pipeline enhanced with document grounding, enabling our model to not only generate high-quality answers, but also cite the exact page and source document it drew from.\n","\n","\n","\n","In this notebook, you will:\n","\n","Load and chunk a Dungeons & Dragons adventure PDF\n","\n","Store it in a Chroma vector database with metadata (page, chunk ID, and source document)\n","\n","Query the database using Gemini embeddings\n","\n","Generate conversational, beginner-friendly answers with visible citations\n"]},{"cell_type":"markdown","id":"fa805334","metadata":{"id":"akuOzK4dJl3j","papermill":{"duration":0.005451,"end_time":"2025-08-16T14:52:06.996817","exception":false,"start_time":"2025-08-16T14:52:06.991366","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"code","execution_count":2,"id":"393cb85c","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:52:07.009849Z","iopub.status.busy":"2025-08-16T14:52:07.009445Z","iopub.status.idle":"2025-08-16T14:53:12.478902Z","shell.execute_reply":"2025-08-16T14:53:12.476939Z"},"id":"JbXe7Oodc5dP","papermill":{"duration":65.480739,"end_time":"2025-08-16T14:53:12.483075","exception":false,"start_time":"2025-08-16T14:52:07.002336","status":"completed"},"tags":[]},"outputs":[],"source":["!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n","!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n","!pip install -q pymupdf"]},{"cell_type":"code","execution_count":3,"id":"ef2f4541","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:12.502587Z","iopub.status.busy":"2025-08-16T14:53:12.502094Z","iopub.status.idle":"2025-08-16T14:53:14.239966Z","shell.execute_reply":"2025-08-16T14:53:14.238431Z"},"id":"muuhsDmmKdHi","papermill":{"duration":1.75153,"end_time":"2025-08-16T14:53:14.243006","exception":false,"start_time":"2025-08-16T14:53:12.491476","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'1.7.0'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from google import genai\n","from google.genai import types\n","\n","from IPython.display import Markdown\n","\n","genai.__version__"]},{"cell_type":"code","execution_count":4,"id":"421b064e","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:14.259261Z","iopub.status.busy":"2025-08-16T14:53:14.258263Z","iopub.status.idle":"2025-08-16T14:53:14.433124Z","shell.execute_reply":"2025-08-16T14:53:14.431811Z"},"id":"ysayz8skEfBW","papermill":{"duration":0.186602,"end_time":"2025-08-16T14:53:14.436268","exception":false,"start_time":"2025-08-16T14:53:14.249666","status":"completed"},"tags":[]},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","\n","GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"]},{"cell_type":"markdown","id":"f449e886","metadata":{"id":"fegnGFpMS4AI","papermill":{"duration":0.00596,"end_time":"2025-08-16T14:53:14.449145","exception":false,"start_time":"2025-08-16T14:53:14.443185","status":"completed"},"tags":[]},"source":["### Checking for Embedding-Supported Gemini Models\n","\n","Before we can embed our documents and queries, we need to verify which Gemini models support embedding.\n","\n","The code below initializes the Gemini client using your API key and lists all available models that support the embedContent action. This ensures you're selecting a model that's compatible with vector embedding for use in your RAG pipeline.\n","\n","We’ll be using one of these models to generate vector embeddings for both our Dungeons & Dragons document chunks and user questions."]},{"cell_type":"code","execution_count":5,"id":"79ec5a72","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:14.463981Z","iopub.status.busy":"2025-08-16T14:53:14.463452Z","iopub.status.idle":"2025-08-16T14:53:14.975571Z","shell.execute_reply":"2025-08-16T14:53:14.974315Z"},"id":"Km5d13_FS2Q_","papermill":{"duration":0.523553,"end_time":"2025-08-16T14:53:14.978796","exception":false,"start_time":"2025-08-16T14:53:14.455243","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["models/embedding-001\n","models/text-embedding-004\n","models/gemini-embedding-exp-03-07\n","models/gemini-embedding-exp\n","models/gemini-embedding-001\n"]}],"source":["client = genai.Client(api_key=GOOGLE_API_KEY)\n","\n","for m in client.models.list():\n","    if \"embedContent\" in m.supported_actions:\n","        print(m.name)"]},{"cell_type":"markdown","id":"217a6e59","metadata":{"id":"3XWKXoXwOGxS","papermill":{"duration":0.006316,"end_time":"2025-08-16T14:53:14.991691","exception":false,"start_time":"2025-08-16T14:53:14.985375","status":"completed"},"tags":[]},"source":["### Data\n","\n","Here is the documents you will use to create an embedding database."]},{"cell_type":"code","execution_count":6,"id":"cfa7a76e","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:15.007137Z","iopub.status.busy":"2025-08-16T14:53:15.006247Z","iopub.status.idle":"2025-08-16T14:53:16.163417Z","shell.execute_reply":"2025-08-16T14:53:16.161833Z"},"id":"k8nsbhFJKmG-","papermill":{"duration":1.168159,"end_time":"2025-08-16T14:53:16.166268","exception":false,"start_time":"2025-08-16T14:53:14.998109","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{'page': 1, 'chunk_id': 0, 'source_doc': 'DRA17_northernpalace.pdf'}\n"]}],"source":["import os\n","import fitz  # PyMuPDF\n","\n","# List of all PDFs you want to index\n","pdf_paths = [\n","    \"/kaggle/input/dnd-northern-palace/DRA17_northernpalace.pdf\",\n","    \"/kaggle/input/dnd-file-oneshots/5E_Wolves_Of_Welton.pdf\",\n","    \"/kaggle/input/dnd-file-oneshots/the_wild_sheep_chase_v2.pdf\"\n","]\n","\n","chunks = []\n","chunk_id_counter = 0\n","\n","for pdf_path in pdf_paths:\n","    source_doc = os.path.basename(pdf_path)\n","    \n","    try:\n","        doc = fitz.open(pdf_path)\n","    except Exception as e:\n","        print(f\"Failed to open {source_doc}: {e}\")\n","        continue  # skip to next doc\n","\n","    for i, page in enumerate(doc):\n","        page_text = page.get_text()\n","        page_text = page_text.replace('\\xa0', ' ').strip()\n","\n","        for section in page_text.split('\\n\\n'):\n","            clean = section.strip()\n","            if len(clean) > 30:\n","                chunks.append({\n","                    \"text\": clean,\n","                    \"page\": i + 1,\n","                    \"source_doc\": source_doc,\n","                    \"chunk_id\": chunk_id_counter\n","                })\n","                chunk_id_counter += 1\n","\n","# Prepare data for ChromaDB\n","documents = [chunk[\"text\"] for chunk in chunks]\n","metadatas = [{\"page\": chunk[\"page\"], \"chunk_id\": chunk[\"chunk_id\"], \"source_doc\": chunk[\"source_doc\"]}\n","             for chunk in chunks]\n","ids = [str(chunk[\"chunk_id\"]) for chunk in chunks]\n","\n","# Preview a sample chunk\n","print(metadatas[0])\n","\n","\n"]},{"cell_type":"markdown","id":"fb459a00","metadata":{"id":"yDzxArLeOexD","papermill":{"duration":0.006036,"end_time":"2025-08-16T14:53:16.179201","exception":false,"start_time":"2025-08-16T14:53:16.173165","status":"completed"},"tags":[]},"source":["## Creating the embedding database with ChromaDB\n","\n","Create a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. In this task, you are implementing a retrieval system, so the `task_type` for generating the *document* embeddings is `retrieval_document`. Later, you will use `retrieval_query` for the *query* embeddings. Check out the [API reference](https://ai.google.dev/api/embeddings#v1beta.TaskType) for the full list of supported tasks.\n","\n","Key words: Documents are the items that are in the database. They are inserted first, and later retrieved. Queries are the textual search terms and can be simple keywords or textual descriptions of the desired documents."]},{"cell_type":"code","execution_count":7,"id":"03cd0736","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:16.195222Z","iopub.status.busy":"2025-08-16T14:53:16.193626Z","iopub.status.idle":"2025-08-16T14:53:17.417618Z","shell.execute_reply":"2025-08-16T14:53:17.416279Z"},"id":"mF7Uu1kCQsT0","papermill":{"duration":1.235263,"end_time":"2025-08-16T14:53:17.420841","exception":false,"start_time":"2025-08-16T14:53:16.185578","status":"completed"},"tags":[]},"outputs":[],"source":["from chromadb import Documents, EmbeddingFunction, Embeddings\n","from google.api_core import retry\n","\n","from google.genai import types\n","\n","\n","# Define a helper to retry when per-minute quota is reached.\n","is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n","\n","\n","class GeminiEmbeddingFunction(EmbeddingFunction):\n","    # Specify whether to generate embeddings for documents, or queries\n","    document_mode = True\n","\n","    @retry.Retry(predicate=is_retriable)\n","    def __call__(self, input: Documents) -> Embeddings:\n","        if self.document_mode:\n","            embedding_task = \"retrieval_document\"\n","        else:\n","            embedding_task = \"retrieval_query\"\n","\n","        response = client.models.embed_content(\n","            model=\"models/text-embedding-004\",\n","            contents=input,\n","            config=types.EmbedContentConfig(\n","                task_type=embedding_task,\n","            ),\n","        )\n","        return [e.values for e in response.embeddings]"]},{"cell_type":"markdown","id":"9de4cda5","metadata":{"id":"HrDWLyopPNBf","papermill":{"duration":0.006194,"end_time":"2025-08-16T14:53:17.434122","exception":false,"start_time":"2025-08-16T14:53:17.427928","status":"completed"},"tags":[]},"source":["Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the documents you defined above."]},{"cell_type":"code","execution_count":8,"id":"6b1dceb7","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:17.449918Z","iopub.status.busy":"2025-08-16T14:53:17.449101Z","iopub.status.idle":"2025-08-16T14:53:18.295126Z","shell.execute_reply":"2025-08-16T14:53:18.29371Z"},"id":"OITXgxZlLoXU","papermill":{"duration":0.857821,"end_time":"2025-08-16T14:53:18.298358","exception":false,"start_time":"2025-08-16T14:53:17.440537","status":"completed"},"tags":[]},"outputs":[],"source":["import chromadb\n","\n","DB_NAME = \"googlecardb\"\n","\n","embed_fn = GeminiEmbeddingFunction()\n","embed_fn.document_mode = True\n","\n","chroma_client = chromadb.Client()\n","db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n","\n","db.add(\n","    documents=documents,\n","    metadatas=metadatas,\n","    ids=ids\n",")\n"]},{"cell_type":"markdown","id":"ec8e3550","metadata":{"id":"2QbwFgfXp-fL","papermill":{"duration":0.005935,"end_time":"2025-08-16T14:53:18.310997","exception":false,"start_time":"2025-08-16T14:53:18.305062","status":"completed"},"tags":[]},"source":["Confirm that the data was inserted by looking at the database."]},{"cell_type":"code","execution_count":9,"id":"79a93cbb","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.326077Z","iopub.status.busy":"2025-08-16T14:53:18.325518Z","iopub.status.idle":"2025-08-16T14:53:18.338219Z","shell.execute_reply":"2025-08-16T14:53:18.336812Z"},"id":"kQ9PHUL_l-hf","papermill":{"duration":0.02396,"end_time":"2025-08-16T14:53:18.34128","exception":false,"start_time":"2025-08-16T14:53:18.31732","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["25"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["db.count()\n","# You can peek at the data too.\n","#db.peek(1)"]},{"cell_type":"markdown","id":"478325fe","metadata":{"id":"Tu5zRErgsQ8u","papermill":{"duration":0.006103,"end_time":"2025-08-16T14:53:18.354277","exception":false,"start_time":"2025-08-16T14:53:18.348174","status":"completed"},"tags":[]},"source":["## Retrieval: Find relevant documents\n","\n","To search the Chroma database, call the `query` method. Note that you also switch to the `retrieval_query` mode of embedding generation.\n"]},{"cell_type":"code","execution_count":10,"id":"738ecb25","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.370434Z","iopub.status.busy":"2025-08-16T14:53:18.369911Z","iopub.status.idle":"2025-08-16T14:53:18.381178Z","shell.execute_reply":"2025-08-16T14:53:18.379574Z"},"id":"gQdJMbTSLtKE","papermill":{"duration":0.022427,"end_time":"2025-08-16T14:53:18.383999","exception":false,"start_time":"2025-08-16T14:53:18.361572","status":"completed"},"tags":[]},"outputs":[],"source":["def retrieve_passages(query, k=5, topic_hint=None):\n","    embed_fn.document_mode = False\n","    result = db.query(query_texts=[query], n_results=k * 4)  # Get more to allow filtering\n","    all_passages = result[\"documents\"][0]\n","    all_metadatas = result[\"metadatas\"][0]\n","\n","    # Normalize topic hint for comparison\n","    def matches_topic(meta, hint):\n","        source = meta.get(\"source_doc\", \"\").lower()\n","        return hint.lower() in source\n","\n","    # Apply topic filtering\n","    if topic_hint:\n","        filtered = [(p, m) for p, m in zip(all_passages, all_metadatas) if matches_topic(m, topic_hint)]\n","\n","        if filtered:\n","            top_k = filtered[:k]\n","            all_passages, all_metadatas = zip(*top_k)\n","        else:\n","            # No match found, fallback to unfiltered top-k\n","            all_passages, all_metadatas = all_passages[:k], all_metadatas[:k]\n","    else:\n","        # No topic hint, return top-k directly\n","        all_passages, all_metadatas = all_passages[:k], all_metadatas[:k]\n","\n","    return list(all_passages), list(all_metadatas)\n"]},{"cell_type":"markdown","id":"9eb158a9","metadata":{"id":"s8PNRMpOQkm5","papermill":{"duration":0.007917,"end_time":"2025-08-16T14:53:18.398718","exception":false,"start_time":"2025-08-16T14:53:18.390801","status":"completed"},"tags":[]},"source":["## Augmented generation: Answer the question\n","\n","Now that you have found a relevant passage from the set of documents (the *retrieval* step), you can now assemble a generation prompt to have the Gemini API *generate* a final answer. Note that in this example only a single passage was retrieved. In practice, especially when the size of your underlying data is large, you will want to retrieve more than one result and let the Gemini model determine what passages are relevant in answering the question. For this reason it's OK if some retrieved passages are not directly related to the question - this generation step should ignore them."]},{"cell_type":"code","execution_count":11,"id":"1c38c3df","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.418479Z","iopub.status.busy":"2025-08-16T14:53:18.417936Z","iopub.status.idle":"2025-08-16T14:53:18.433209Z","shell.execute_reply":"2025-08-16T14:53:18.430746Z"},"id":"b6_Y-GOymaXu","papermill":{"duration":0.027978,"end_time":"2025-08-16T14:53:18.436937","exception":false,"start_time":"2025-08-16T14:53:18.408959","status":"completed"},"tags":[]},"outputs":[],"source":["from collections import defaultdict\n","\n","def build_prompt(query, retrieved_passages, metadatas):\n","    query_oneline = query.replace(\"\\n\", \" \")\n","\n","    prompt = f\"\"\"\n","You are a knowledgeable and friendly Dungeons & Dragons assistant. Use only the reference passages provided below to answer the question. \n","If the answer is not clearly supported by the passages, say you’re not sure rather than making something up.\n","\n","Be detailed, but use a conversational tone — imagine you're helping a new player or Dungeon Master. \n","Explain any terms that may be unclear to beginners, and try to include the context where appropriate.\n","\n","Here are some examples:\n","\n","---\n","\n","QUESTION: What is the Challenge Rating (CR) of a Beholder?\n","\n","REFERENCE PASSAGE: A Beholder is a terrifying aberration with a Challenge Rating (CR) of 13. It can fly and shoot devastating eye rays.\n","\n","ANSWER: A Beholder has a Challenge Rating of 13. This means it’s a very dangerous monster—powerful enough to challenge an entire party of adventurers.\n","\n","---\n","\n","QUESTION: What is a spell slot?\n","\n","REFERENCE PASSAGE: Spell slots represent the number of spells a caster can use per day. When a spell is cast, it consumes a slot of its level or higher.\n","\n","ANSWER: A spell slot is a resource that limits how many spells a magic user can cast. Each time a spell is used, one of the available slots is used up. Stronger spells require higher-level slots.\n","\n","---\n","\n","Now answer the following question:\n","\n","QUESTION: {query_oneline}\n","\"\"\"\n","\n","    # Group by document\n","    grouped_passages = defaultdict(list)\n","    for passage, meta in zip(retrieved_passages, metadatas):\n","        doc = meta.get(\"source_doc\", \"Unknown Document\")\n","        grouped_passages[doc].append((meta.get(\"page\"), passage))\n","\n","    for doc_name, entries in grouped_passages.items():\n","        for page, passage in entries:\n","            passage_oneline = passage.replace(\"\\n\", \" \").strip()\n","            if len(passage_oneline) > 1000:\n","                passage_oneline = passage_oneline[:1000] + \"...\"\n","            prompt += f\"\\nREFERENCE PASSAGE ({doc_name}, Page {page}): {passage_oneline}\"\n","\n","    prompt += \"\\n\\nNow, using only the reference passages, write your answer below:\\n\\nANSWER:\"\n","    return prompt"]},{"cell_type":"markdown","id":"70d05225","metadata":{"id":"VRy6yXzcPxLB","papermill":{"duration":0.010068,"end_time":"2025-08-16T14:53:18.459099","exception":false,"start_time":"2025-08-16T14:53:18.449031","status":"completed"},"tags":[]},"source":["Now use the `generate_content` method to to generate an answer to the question."]},{"cell_type":"code","execution_count":12,"id":"d6b84593","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.481432Z","iopub.status.busy":"2025-08-16T14:53:18.480432Z","iopub.status.idle":"2025-08-16T14:53:18.493211Z","shell.execute_reply":"2025-08-16T14:53:18.491789Z"},"id":"EwfyxFM6Giy9","papermill":{"duration":0.028852,"end_time":"2025-08-16T14:53:18.498033","exception":false,"start_time":"2025-08-16T14:53:18.469181","status":"completed"},"tags":[]},"outputs":[],"source":["from IPython.display import Markdown\n","\n","def generate_and_display_answer(prompt, metadatas):\n","    # Generate answer using Gemini\n","    response = client.models.generate_content(\n","        model=\"gemini-2.0-flash\",\n","        contents=prompt\n","    )\n","    answer = response.text.strip()\n","\n","    # Deduplicate and format sources\n","    seen = set()\n","    source_info_lines = []\n","    for meta in metadatas:\n","        key = (meta.get(\"source_doc\"), meta.get(\"page\"), meta.get(\"chunk_id\"))\n","        if key not in seen:\n","            seen.add(key)\n","            source_info_lines.append(\n","                f\"- {meta.get('source_doc')} (Page {meta.get('page')}, Chunk {meta.get('chunk_id')})\"\n","            )\n","\n","    source_info = \"\\n\".join(source_info_lines)\n","\n","    # Display result\n","    final_output = f\"{answer}\\n\\n---\\n**Sources:**\\n{source_info}\"\n","    display(Markdown(final_output))\n","\n","    return answer, source_info\n"]},{"cell_type":"code","execution_count":13,"id":"0293439d","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.517863Z","iopub.status.busy":"2025-08-16T14:53:18.517307Z","iopub.status.idle":"2025-08-16T14:53:18.534357Z","shell.execute_reply":"2025-08-16T14:53:18.533062Z"},"papermill":{"duration":0.029775,"end_time":"2025-08-16T14:53:18.537133","exception":false,"start_time":"2025-08-16T14:53:18.507358","status":"completed"},"tags":[]},"outputs":[],"source":["import re\n","import json\n","from IPython.display import Markdown\n","\n","# === Campaign Keywords ===\n","campaign_keywords = {\n","    \"wolves of welton\": \"wolves\",\n","    \"nicholas\": \"nicholas\",\n","    \"northern palace\": \"palace\",\n","    \"wild sheep chase\": \"sheep\",\n","    \"sheep\": \"sheep\"\n","}\n","\n","# === Fuzzy Topic Detection ===\n","def detect_topic(query, known_campaigns, current_topic=None):\n","    query = query.lower()\n","    \n","    # Direct override (e.g. \"focus on Nicholas\")\n","    match = re.search(r\"focus on (.+)\", query)\n","    if match:\n","        requested = match.group(1).strip()\n","        for phrase, topic_key in known_campaigns.items():\n","            if re.search(rf\"\\b{re.escape(phrase)}\\b\", requested):\n","                return topic_key\n","    \n","    # Only trigger if no topic is set or user says something like \"let's talk about\"\n","    if current_topic is None or any(p in query for p in [\"let's talk about\", \"tell me about\", \"start with\"]):\n","        for phrase, topic_key in known_campaigns.items():\n","            if re.search(rf\"\\b{re.escape(phrase)}\\b\", query):\n","                return topic_key\n","    \n","    return current_topic  # Default: preserve current topic\n","\n","def run_chat_assistant():\n","    global chat_history, current_topic\n","    if \"chat_history\" not in globals():\n","        chat_history = []\n","    if \"current_topic\" not in globals():\n","        current_topic = None\n","\n","    print(\"🧙 Welcome to the D&D Assistant!\")\n","    print(\"You can ask questions about adventures or use the following commands:\")\n","    print(\"• @summarize <topic>   — summarize past answers about a topic\")\n","    print(\"• @rerun <k>           — re-run last query with k chunks\")\n","    print(\"• @truncate <n>        — keep last n messages\")\n","    print(\"• @save <file.json>    — save chat history\")\n","    print(\"• @reload <file.json>  — reload chat history\")\n","    print(\"• @campaigns           — list available adventure PDFs\")\n","    print(\"• clear topic / reset topic / exit\\n\")\n","\n","    while True:\n","        query = input(\"💬 You: \").strip()\n","\n","        # === Exit\n","        if query.lower() == \"exit\":\n","            print(\"🧝‍♂️ Assistant: Farewell, adventurer!\")\n","            break\n","\n","        # === Clear topic\n","        if query.lower() in {\"clear topic\", \"reset topic\"}:\n","            current_topic = None\n","            print(\"🧹 Topic has been cleared.\")\n","            continue\n","\n","        # === Function-calling agent commands\n","        if query.startswith(\"@\") and route_agent_command(query):\n","            continue\n","\n","        # === Normal RAG assistant flow\n","        chat_history.append({\"role\": \"user\", \"content\": query})\n","\n","        # Detect topic\n","        new_topic = detect_topic(query, campaign_keywords, current_topic)\n","        if new_topic != current_topic:\n","            current_topic = new_topic\n","            print(f\"📌 Topic set to: {current_topic.title() if current_topic else 'None'}\")\n","\n","        print(f\"\\n📚 Active Topic: {current_topic.title() if current_topic else 'None'}\")\n","\n","        # RAG steps\n","        retrieved_passages, metadatas = retrieve_passages(query, k=15, topic_hint=current_topic)\n","        prompt = build_prompt(query, retrieved_passages, metadatas)\n","        answer, source_info = generate_and_display_answer(prompt, metadatas)\n","        \n","        # Store in chat history silently\n","        chat_history.append({\n","            \"role\": \"assistant\",\n","            \"content\": answer,\n","            \"sources\": source_info\n","        })\n","        \n","        # Only show the latest response visibly\n","        print(f\"\\n🧝‍♂️ Assistant:\\n{answer.strip()}\\n\")\n","        print(f\"📎 Sources:\\n{source_info.strip()}\\n\")\n","\n","\n","# === Save chat history anytime\n","def save_chat_history(filename=\"chat_history.json\"):\n","    with open(filename, \"w\") as f:\n","        json.dump(chat_history, f, indent=2)\n","    print(f\"💾 Chat history saved to {filename}\")\n"]},{"cell_type":"code","execution_count":14,"id":"23ee2fb1","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.552921Z","iopub.status.busy":"2025-08-16T14:53:18.551631Z","iopub.status.idle":"2025-08-16T14:53:18.557382Z","shell.execute_reply":"2025-08-16T14:53:18.55608Z"},"papermill":{"duration":0.01646,"end_time":"2025-08-16T14:53:18.560045","exception":false,"start_time":"2025-08-16T14:53:18.543585","status":"completed"},"tags":[]},"outputs":[],"source":["#run_chat_assistant()"]},{"cell_type":"code","execution_count":null,"id":"50bb22cd","metadata":{"papermill":{"duration":0.006232,"end_time":"2025-08-16T14:53:18.573107","exception":false,"start_time":"2025-08-16T14:53:18.566875","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"id":"65dc992e","metadata":{"execution":{"iopub.execute_input":"2025-08-16T14:53:18.588384Z","iopub.status.busy":"2025-08-16T14:53:18.587915Z","iopub.status.idle":"2025-08-16T14:53:18.593319Z","shell.execute_reply":"2025-08-16T14:53:18.592066Z"},"papermill":{"duration":0.016259,"end_time":"2025-08-16T14:53:18.595917","exception":false,"start_time":"2025-08-16T14:53:18.579658","status":"completed"},"tags":[]},"outputs":[],"source":["# from collections import Counter\n","# sources = [meta[\"source_doc\"] for meta in metadatas]\n","# print(Counter(sources))"]}],"metadata":{"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7169454,"sourceId":11444321,"sourceType":"datasetVersion"},{"datasetId":7190806,"sourceId":11473768,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":76.529933,"end_time":"2025-08-16T14:53:19.932229","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-16T14:52:03.402296","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}